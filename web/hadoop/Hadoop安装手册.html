<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hadoop安装手册</title>
    <style>
        body {
            width: 800px;
        }

        .head {
            position: relative;
            left: 350px;
        }

        .center {
            position: relative;
            left: 250px;
        }

        .center_head {
            font-size: 30px;
        }
    </style>
</head>

<body>
    <center>
        <h1>Hadoop安装手册</h1>
    </center>
    <div class="head">
        <h2>centos7安装</h2>
        <h2>系统配置</h2>
        <h2>安装jdk</h2>
        <h2>克隆</h2>
        <h2>设置免密登录</h2>
        <h2>安装Hadoop</h2>
        <h2>安装Hive</h2>
        <h2>安装Mysql</h2>
        <h2>安装zookeeper</h2>
        <h2>安装Hbase</h2>
        <h2>安装Spark</h2>
        <h2>安装Scala</h2>
        <h2>安装Sqoop</h2>
    </div>
    <div class="center">
        <div class="center_hadoop">
            <p class="center_head">一、centos7安装</p>
            <p>请参考Linux基础的书籍</p>
        </div>
        <div class="center_path">
            <p class="center_head">二、系统配置</p>
            <p>1、配置时钟同步</p>
            使用Linux命令配置<br /><br />
            首先进入超级用户，在命令行输入：su root<br /><br />
            然后再输入：crontab -e<br /><br />
            该命令是 vi 编辑命令，按 i 进入插入模式，按 Esc，然后键入:wq 保存退出<br /><br />
            键入下面的一行代码，输入 i，进入插入模式（星号之间和前后都有空格）<br /><br />
            0 1 * * * /usr/sbin/ntpdate cn.pool.ntp.org<br /><br />
            <p>2、配置主机名</p>
            使用 gedit 编辑主机名，如果不可以使用 gedit，请直接使用 vi 编辑器（后面用到 gedit 的地方也同此处处理一致）。<br /><br />
            在命令行输入：gedit /etc/sysconfig/network<br /><br />
            配置信息如下：<br /><br />
            NETWORKING=yes #启动网络<br /><br />
            HOSTNAME=master #主机名<br /><br />
            接着重启网络服务，输入：service network restart<br /><br />
            <p>2、配置静态IP</p>
            VMWare 编辑菜单 --> 虚拟网络设置<br /><br />
            删除VMnet8<br /><br />
            添加VMnet8 <br /><br />
            修改模式为NAT<br /><br />
            应用<br /><br />
            <img src="./img/network1.png" alt="">
            <p>修改配置文件：gedit /etc/sysconfig/network-scripts/ifcfg-ens33 </p>
            将以下配置添加再文件中(文件已有的配置则将其修改，没有的进行添加)：<br /><br />
            BOOTPROTO=static # 使用静态IP地址，默认为dhcp<br /><br />
            ONBOOT=yes #是否开机启用,默认值为no<br /><br />
            IPADDR=192.168.11.110 # 设置的静态IP地址<br /><br />
            GATEWAY=192.168.11.2 # 网关地址<br /><br />
            NETMASK=255.255.255.0 # 子网掩码<br /><br />
            DNS1=8.8.8.8 # DNS服务器<br /><br />
            保存后退出<br /><br />
            保存后退出<br /><br />
            保存后退出<br /><br />
            接着重启网络服务，输入：service network restart<br /><br />
            <p>3、配置hosts列表</p>
            使用gedit命令编辑hosts看列表：gedit /etc/hosts
            将下面三行添加到/etc/hosts 文件中：<br /><br />
            192.168.11.110 master<br><br>
            192.168.11.120 slave1<br><br>
            192.168.11.130 slave2<br><br>
            (slave1和slave2可以在现在配置也可以在克隆后再配置)master和slave1、slave2代表你的主机名
            <p>4、接着重启网络服务，输入：service network restart</p>
            <p>5、关闭防火墙<br><br>
                systemctl stop firewalld.service <br><br>
                systemctl disable firewalld.service<br /><br />
            </p>
        </div>
        <div class="center_jdk">
            <p class="center_head">三、jdk安装</p>
            <p>1、使用xshell上传jdk压缩包<br /><br />
                xshell使用可参考这个网站：https://blog.csdn.net/qust_gosuccess/article/details/86003565<br /><br />
            </p>
            <p>2、解压jdk：tar -xvf 你的jdk文件</p>
            <p>3、配置环境变量(/etc/profile ~/.bashrc ~/.bash_profile )</p>
            <p>4、随便选择一个上述文件夹使用gedit命令进行编辑,这里以~/.bash_profile为例(后面所有的环境配置都必须配置再你现在配置的文件下)将以下配置添加或覆盖在当前文件：<br /><br />
                export JAVA_HOME=/home/yznaisy/hadoop/jdk1.8.0_141<br /><br />
                export PATH=$JAVA_HOME/bin:$PATH
            </p>
            <p>5、使用source命令来使你的配置文件立即生效，如：source ~/.bash_profile</p>
            <p>6、使用java -version来测试jdk是否安装成功</p>
        </div>
        <div class="center_copy">
            <p class="center_head">四、克隆</p>
            <p>1、关机</p>
            <p>2、右键-->管理-->克隆</p>
            <p></p>
            <p>克隆完成后需要修改你的IP地址及主机名</p>
        </div>
        <div class="center_ssh">
            <p class="center_head">五、设置免密登录</p>
            <p>都必须再普通用户下进行下面的操作</p>
            <p>1、在终端生成密钥，命令如下（一路点击回车生成密钥）：<br><br>
                ssh-keygen -t rsa <br><br>
                2、复制公钥文件<br><br>
                cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys<br><br>
                3、修改 authorized_keys 文件的权限，命令如下：<br><br>
                chmod 600 ~/.ssh/authorized_keys<br><br>
                4、将三台主机都按上面的操作生成密钥，然后将slave1和slave2 authorized_keys文件中的内容复制在master的authorized_keys文件中（(注意不是覆盖) <br><br>
                然后使用命令将master上的authorized_keys文件发送到slave1和slave2上，命令如下：<br><br>
                scp -r ~/.ssh/authorized_keys 你主机的用户名@slave:~/ <br><br>
                5、验证免密登录,命令如下：<br><br>
                ssh slave1
            </p>
        </div>
        <div class="center_hadoop">
            <p class="center_head">六、安装Hadoop</p>
            <p>1、使用xshell上传Hadoop压缩包</p>
            <p>2、同样使用tar命令解压Hadoop<br /><br />
                将解压后的文件夹重命名为hadoop，如：mv hadoop-2.5.2 hadoop<br /><br />
            </p>
            <p>3、使用cd命令进入的Hadoop文件夹如：cd /hadoop-2.7.7/etc/hadoop</p>
            <p>4、配置Hadoop文件</p>
            <p>4.1配置 hadoop-env.sh<br /><br />
                使用gedit对文件进行编辑：<br /><br />
                在文件中找到：<br /><br />
                export JAVA_HOME=${JAVA_HOME}<br /><br />
                将其修改为：<br /><br />
                export JAVA_HOME=/home/yznaisy/hadoop/jdk1.8.0_141<br /><br />
                然后保存文件。<br /><br />
            </p>
            <p>4.2配置yarn-env.sh<br /><br />
                在文件的靠前的部分找到下面的一行代码：<br /><br />
                # export JAVA_HOME=/home/y/libexec/jdk1.6.0/<br /><br />
                将这行代码修改为下面的代码（将#号去掉）<br /><br />
                然后保存文件。<br /><br />
            </p>
            <p>
                4.3配置core-site.xml <br /><br />
                用下面的代码替换 core-site.xml 中的内容：<br /><br />
                <img src="./img/core-site.xml.png" alt="">
            </p>
            <p>
                4.4配置hdfs-site.xml<br /><br />
                用下面的代码替换 hdfs-site.xml 中的内容：<br /><br />
                <img src="./img/hdfs-site.xml.png" alt="">
            </p>
            <p>4.5配置yarn-site.xml<br /><br />
                用下面的代码替换yarn-site.xml中的内容:<br /><br />
                <img src="./img/yarn-site.xml.png" alt="">
            </p>
            <p>4.6配置mapred-site.xml<br /><br />
                复制mapred-site-template.xml 文件：<br /><br />
                cp mapred-site.xml.template mapred-site.xml <br /><br />
                用下面的代码替换 mapred-site.xml 中的内容:<br /><br />
                <img src="./img/mapred-site.xml.png" alt="">
            </p>
            <p>4.7配置slaves<br /><br />
                使用 gedit 编辑：<br /><br />
                用下面的代码替换 slaves 中的内容：<br /><br />
                slave1<br /><br />
                slave2<br /><br />
            </p>
            <p>4.7配置环境变量<br /><br />
                在你刚才配置环境变量的文件中添加如下配置：<br /><br />
                export HADOOP_HOME=Hadoop的安装位置，如：/home/yznaisy/hadoop<br /><br />
                export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH<br /><br />
                将配置好的Hadoop文件和环境变量发送到slave1和slave2<br /><br />
            </p>
            <p>4.8创建数据目录<br /><br />
                使用mkdir来创建目录，如：mkdir /home/yznaisy/hadoop/hadoopdata 这个路径与你配置hadoop文件的路径相同(注意三台主机都需要创建目录)<br /><br />
            </p>
            <p>4.9格式化文件系统
                hdfs namenode -foramt
            </p>
            <p>4.10启动Hadoop<br /><br />
                进入Hadoop安装目录使用命令来启动Hadoop，命令如下：<br /><br />
                ./sbin/start-all.sh<br /><br />
            </p>
            <p>4.11查看进程是否启动<br /><br />
                使用jps查看<br /><br />
                <img src="./img/hadoop_jps.png" alt=""><br /><br />
                Web UI 查看集群是否成功启动<br /><br />
                在 master 上启动 Firefox 浏览器，在浏览器地址栏中输入输入 http://master:50070/，检查<br /><br />
                namenode 和 datanode 是否正常。UI 页面如下图所示。<br /><br />
                <img src="./img/hadoop_50070.png" alt=""><br /><br /><br /><br />
                <img src="./img/hadoop_18088.png" alt="">
            </p>
        </div>
        <div class="center_hive">
            <p class="center_head">七、hive安装</p>
            <p>1、上传hive压缩包</p>
            <p>2、解压hive</p>
            <p>3、改名为hive</p>
            <p>4、修改hive配置文件<br /><br />
                Hive安装好后，是没有自带hive-site.xml文件。<br /><br />
                进入hive/conf/文件下首先复制hive-default.xml.template到hive-default.xml作为全局配置文件.自己创建hive-site.xml作为可覆盖配置文件</p>
            <p>5、编辑hive-site.xml文件,添加如下内容:
                <img src="./img/hive.png" alt="">
            </p>
            <p>6、连接mysql<br /><br />
                将mysql-connector-java-x.x.x-bin.jar复制在hive/lib/目录下<br /><br />
            </p>
            <p>7、配置环境变量<br /><br />
                export HIVE_HOME=/home/yznaisy/hadoop/hive<br /><br />
                export PATH=$PATH:$HIVE_HOME/bin<br /><br />
                export HADOOP_HOME=/home/yznaisy/hadoop/hadoop<br /><br />
            </p>
            <p>8、将配置好的hive文件和环境变量发送到slave1和slave2<br /><br />
                不要启动hive，还需要安装MySQL！！！！<br /><br />
                不要启动hive，还需要安装MySQL！！！！<br /><br />
                不要启动hive，还需要安装MySQL！！！！<br /><br />
            </p>
        </div>
        <div class="center_mysql">
            <p class="center_head">八、安装MySQL</p>
            <p>1、由于CentOS 的yum源中没有mysql，需要到mysql的官网下载yum repo配置文件</p>
            <p>下载命令：wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm</p>
            <p>2、然后进行repo的安装：</p>
            <p>rpm -ivh mysql57-community-release-el7-9.noarch.rpm<br /><br />
                执行完成后会在/etc/yum.repos.d/目录下生成两个repo文件mysql-community.repo mysql-community-source.repo<br /><br />
            </p>
            <p>3、使用yum命令即可完成安装<br /><br />
                注意：必须进入到 /etc/yum.repos.d/目录后再执行以下脚本<br /><br />
                安装命令：yum install mysql-server<br /><br />
                设置开机自启动<br /><br />
                systemctl enable mysqld<br /><br />
                启动msyql：<br /><br />
                systemctl start mysqld <br /><br />
                初始化MySQL<br /><br />
                mysql_secure_installation（能回车的回车）<br /><br />
            </p>
            <p>4、修改mysql密码<br /><br />
                重置密码的第一步就是跳过MySQL的密码认证过程，方法如下：<br /><br />
                #vim /etc/my.cnf(注：windows下修改的是my.ini)<br /><br />
                在[mysqld]后面任意一行添加“skip-grant-tables”用来跳过密码验证的过程，退出保存即可<br /><br />
                重启mysql： systemctl restart mysqld<br /><br />
                免密登录：mysql -u root -p<br /><br />
                进入数据库：use mysql<br /><br />
                修改root密码，命令如下：<br /><br />
                update user set authentication_string = password('这里输入新密码'),password_last_changed=now() where
                user='root';<br /><br />
                退出mysql数据库：quit；<br /><br />
                再次修改配置文件：vi /etc/my.cnf 删除 skip-grant-tables 保存退出<br /><br />
                重启mysql服务即可<br /><br />
            </p>
            <p>5、登录mysql<br /><br />
                然后执行 mysql -uroot -p ，输入上面的到的密码进入，用该密码登录后，必须马上修改新的密码，不然会报如下错误：<br /><br />
                mysql> use mysql;<br /><br />
                ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this
                statement. <br /><br />
                错误信息为：在执行此语句之前，必须使用ALTER USER语句重置密码。<br /><br />
                如果你想要设置一个简单的测试密码的话，比如设置为123456，会提示这个错误，报错的意思就是你的密码不符合要求<br /><br />
                mysql> alter user 'root'@'localhost' identified by '123456';<br /><br />
                ERROR 1819 (HY000): Your password does not satisfy the current policy requirements<br /><br />
                错误信息为：您的密码不符合当前的策略要求<br /><br />
                查看 mysql 初始的密码策略，<br /><br />
                输入语句 “ SHOW VARIABLES LIKE 'validate_password%'; ” 进行查看<br /><br />
                首先需要设置密码的验证强度等级，设置 validate_password_policy 的全局参数为 LOW 即可，<br /><br />
                输入设值语句 “ set global validate_password_policy=LOW; ” 进行设值，<br /><br />
                当前密码长度为 8 ，如果不介意的话就不用修改了，按照通用的来讲，设置为 6 位的密码，设置 validate_password_length 的全局参数为 6 即可，<br /><br />
                输入设值语句 “ set global validate_password_length=6; ” 进行设值，<br /><br />
                现在可以为 mysql 设置简单密码了，只要满足六位的长度即可，<br /><br />
                输入修改语句 “ ALTER USER 'root'@'localhost' IDENTIFIED BY '123456'; ” 可以看到修改成功，表示密码策略修改成功了！！<br /><br />
                关于 mysql 密码策略相关参数；<br /><br />
                1）、validate_password_length 固定密码的总长度；<br /><br />
                2）、validate_password_dictionary_file 指定密码验证的文件路径；<br /><br />
                3）、validate_password_mixed_case_count 整个密码中至少要包含大/小写字母的总个数；<br /><br />
                4）、validate_password_number_count 整个密码中至少要包含阿拉伯数字的个数；<br /><br />
                5）、validate_password_policy 指定密码的强度验证等级，默认为 MEDIUM；<br /><br />
                关于 validate_password_policy 的取值：<br /><br />
                0/LOW：只验证长度；<br /><br />
                1/MEDIUM：验证长度、数字、大小写、特殊字符；<br /><br />
                2/STRONG：验证长度、数字、大小写、特殊字符、字典文件；<br /><br />
                6）、validate_password_special_char_count 整个密码中至少要包含特殊字符的个数；<br /><br />
            </p>
            <p>6、新建hive数据库<br /><br />
                create database hive; <br /><br />
                #这个hive数据库与hive-site.xml中localhost:3306/hive的hive对应，用来保存hive元数据<br /><br />
            </p>
            <p>7、允许MySQL接入hive<br /><br />
                grant all on *.* to hive@localhost identified by 'hive'; <br /><br />
                #将所有数据库的所有表的所有权限赋给hive用户，后面的hive是配置hive-site.xml中配置的连接密码<br /><br />
                flush privileges; <br /><br />
                #刷新mysql系统权限关系表<br /><br />
            </p>
            <p>8、启动hive<br /><br />
                启动hive前一定初始化元数据！！！<br /><br />
                启动hive前一定初始化元数据！！！<br /><br />
                启动hive前一定初始化元数据！！！<br /><br />
                命令如下：<br /><br />
                schematool -dbType mysql -initSchema<br /><br />
                还需要启动metastore:<br /><br />
                hive --service metastore &<br /><br />
                然后就可以启动hive了<br /><br />
            </p>
            <p>9、测试hive<br /><br />
                在hive交互式执行环境中使用sql语句查询数据库:show databases;<br /><br />
                如图表示成功：<br /><br />
                <img src="./img/show databases.png" alt="">
            </p>
        </div>
        <div class="center_zookeeper">
            <p class="center_head">九、zookeeper安装</p>
            <p>1、上传zookeeper压缩包</p>
            <p>2、解压zookeeper</p>
            <p>3、改名为zookeeper</p>
            <p>4、配置zookeeper文件、<br /><br />
                将zoo_sample.cfg修改为zoo.cfg<br /><br />
                编辑zoo.cfg，在最后添加下列代码<br /><br />
                dataDir=/home/yznaisy/hadoop/zookeeper/data<br /><br />
                dataLogDir=/home/yznaisy/hadoop/zookeeper/datalog<br /><br />
                server.1=master:2888:3888<br /><br />
                server.2=slave1:2888:3888<br /><br />
                server.3=slave2:2888:3888<br /><br />
                在zookeeper安装目录下创建文件夹：<br /><br />
                mkdir data<br /><br />
                mkdir datalog<br /><br />
                在master上： <br /><br />
                echo 1 > data/myid<br /><br />
                在slave1上： <br /><br />
                echo 2 > data/myid<br /><br />
                在slave2上： <br /><br />
                echo 3 > data/myid<br /><br />
                配置环境变量：<br /><br />
                export ZOOKEEPER_HOME=/home/yznaisy/hadoop/zookeeper<br /><br />
                export PATH=$PATH:$ZOOKEEPER_HOME/bin<br /><br />
                将配置好的zookeeper文件和环境变量发送到slave1和slave2<br /><br />
            </p>
            <p>5、测试zookeeper是否安装成功<br /><br />
                进入zookeeper安装目录<br /><br />
                ./bin/zkServer.sh start<br /><br />
                ./bin/zkServer.sh status <br /><br />
            </p>
        </div>
        <div class="center_hbase">
            <p class="center_head">九、Hbase安装</p>
            <p>1、上传Hbase压缩包</p>
            <p>2、解压Hbase</p>
            <p>3、改名为hbase</p>
            <p>4、修改Hbase文件<br /><br />
                编辑regionservers在文件中添加：<br /><br />
                master<br /><br />
                slave1<br /><br />
                slave2<br /><br />
                修改hbase-site.xml：
                <img src="./img/hbase-site.xml.png" alt="">
                <br /><br />
                修改hbase-env.sh：<br /><br />
                在hbase-env.sh中添加如下两行:<br /><br />
                export JAVA_HOME=/home/yznaisy/hadoop/hadoop/jdk1.8.0_141<br /><br />
                export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib<br /><br />
                找到如下代码将前面的#号去掉:<br /><br />
                #export HBASE MANAGES ZK=true<br /><br />
            </p>
            <p>5、配置环境变量<br /><br />
                export HBASE_HOME=/home/yznaisy/hadoop/hbase<br /><br />
                export HBASE_CLASSPATH=$HBASE_HOME/conf<br /><br />
                export HBASE_LOG_DIR=$HBASE_HOME/logs<br /><br />
                export PATH=$PATH:$HBASE_HOME/bin<br /><br />
                将配置好的Hbase文件和环境变量发送到slave1和slave2<br /><br />
            </p>
            <p>6、启动Hbase<br /><br />
                进入Hbase目录下./bin/start-habse.sh<br /><br />
                jps查看进程<br /><br />
                关闭Hbase<br /><br />
                ./bin/stop-hbase.sh<br /><br />
                查看Web UI 如同表示成功：
                <img src="./img/hbase_60010.png" alt="">
            </p>
        </div>
        <div class="center_spark">
            <p class="center_head">十、Spark安装</p>
            <p>1、上传Spark安装包</p>
            <p>2、解压Spark</p>
            <p>3、改名为spark</p>
            <p>4、配置环境变量<br /><br />
                export SPARK_HOME=/home/yznaisy/hadoop/spark<br /><br />
                export PATH=$PATH:$SPARK_HOME/bin<br /><br />
            </p>
            <p>5、修改Spark文件<br /><br />
                进入spark/conf/目录下<br /><br />
                将spark-env.sh.template更名为spark-env.sh<br /><br />
                编辑spark-env.sh，在最下方添加如下代码：<br /><br />
                export JAVA_HOME=/home/yznaisy/hadoop/jdk1.8.0_141<br /><br />
                export SPARK_MASTER_HOST=master<br /><br />
                export SPARK_MASTER_PORT=7077 <br /><br />
                将slaves.template更名为slaves<br /><br />
                编辑slaves,使用如下代码覆盖原来的代码:<br /><br />
                master<br /><br />
                slave1<br /><br />
                slave2<br /><br />
                将配置好的Spark文件和环境变量发送到slave1和slave2<br /><br />
            </p>
            <p>6、启动Spark<br /><br />
                启动Spark之前必须启动Hadoop<br /><br />
                ./bin/stop-hbase.sh<br /><br />
                查看Web UI 如同表示成功：
                <img src="./img/spark.png" alt="">
            </p>
        </div>
        <div class="center_scala">
            <p class="center_head">十一、安装Scala</p>
            <p>1、上传Scala压缩包</p>
            <p>2、解压Scala</p>
            <p>3、改名为scala</p>
            <p>4、配置环境变量<br /><br />
                export PATH=$PATH:/home/yznaisy/hadoop/scala/bin<br /><br />
            </p>
            <p>5、启动Scala<br /><br />
                直接在终端输入scala<br /><br />
            </p>
        </div>
        <div class="center_sqoop">
            <p class="center_head">十二、sqoop安装</p>
            <p>1、上传sqoop压缩包</p>
            <p>2、解压sqoop</p>
            <p>3、改名为sqoop</p>
            <p>4、配置环境变量<br /><br />
                export SQOOP_HOME=/home/yznaisy/hadoop/sqoop<br /><br />
                export PATH=$PATH:$SBT_HOME/bin:$SQOOP_HOME/bin<br /><br />
                export CLASSPATH=$CLASSPATH:$SQOOP_HOME/lib<br /><br />
            </p>
            <p>5、配置sqoop文件<br /><br />
                将sqoop-env-template.sh更名为sqoop-env.sh<br /><br />
                编辑sqoop-env.sh，在最后添加如下代码：<br /><br />
                export HADOOP_COMMON_HOME=/home/yznaisy/hadoop/hadoop<br /><br />
                export HADOOP_MAPRED_HOME=/home/yznaisy/hadoop/hadoop<br /><br />
                export HBASE_HOME=/home/yznaisy/hadoop/hbase<br /><br />
                export HIVE_HOME=/home/yznaisy/hadoop/hive<br /><br />
                export ZOOKEEPER_HOME=/home/yznaisy/hadoop/zookeeper<br /><br />
                export ZOOCFGDIR=/home/yznaisy/hadoop/zookeeper/conf<br /><br />
            </p>
            <p>6、连接mysql<br /><br />
                将mysql-connector-java-x.x.x-bin.jar复制在sqoop/bin/目录下<br /><br />
            </p>
            <p>7、验证安装是否成功<br /><br />
                sqoop version<br /><br />
            </p>
            <p></p>
            <p></p>
        </div>
    </div>
</body>

</html>